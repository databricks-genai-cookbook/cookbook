{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a99d4119-ed8a-4cac-9b4f-dedf54349a3d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "(nbs:vector_search_fm_api)=\n",
    "# Foundation Model API Embeddings for Vector Search\n",
    "\n",
    "[Databricks Vector Search](https://docs.databricks.com/en/generative-ai/vector-search.html) is a vector database built into Databricks that offers straightforward integration with the Databricks Foundation Model API embedding models.\n",
    "\n",
    "This notebook walks through the process of setting up a vector index and configuring it to automatically use an embedding model from the Foundation Model API to generate embeddings. It will then show how load some text data into the vector database and how to query the database.\n",
    "\n",
    "To learn more about how Databricks Vector Search works, see the documentation [here](https://docs.databricks.com/en/generative-ai/vector-search.html#how-does-vector-search-work)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a67316b5-1a7c-485b-9828-57154049822b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Setup\n",
    "First, we will install the necessary libraries and set up a temporary catalog/schema/table for this example. If you do not have permissions to create catalogs, you can specify a catalog manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "940d9ef2-d01f-4e69-8f13-dc0203d4afd8",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "%pip install --upgrade --force-reinstall databricks-vectorsearch databricks-genai-inference\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96cbf2ee-09d7-43cd-abfb-3d1cd4078e6c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daniel_liden_databricks_com_20240207_152232_7b118968\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "\n",
    "# Assuming DB_USER is fetched from the Databricks utility\n",
    "DB_USER = dbutils.notebook.entry_point.getDbutils().notebook().getContext().userName().get()\n",
    "\n",
    "# Sanitize the DB_USER by replacing non-alphanumeric characters with underscores\n",
    "DB_USER_SANITIZED = re.sub(r'\\W', '_', DB_USER)\n",
    "\n",
    "# Append a timestamp and a UUID to ensure uniqueness\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "unique_id = str(uuid.uuid4()).split('-')[0]  # Get the first part of the UUID\n",
    "\n",
    "# Create a definitely unique DB_USER identifier\n",
    "DB_USER_UNIQUE = f\"{DB_USER_SANITIZED}_{timestamp}_{unique_id}\"\n",
    "\n",
    "print(DB_USER_UNIQUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c0ba19e-281a-4d1b-ab58-96e4be4c7158",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Define temporary catalog, table, endpoint, and index names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f5c55a7-17a2-4e4a-a922-85e25dbded12",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CATALOG = DB_USER_UNIQUE\n",
    "DB = \"FM_API_EXAMPLES\"\n",
    "VS_ENDPOINT_NAME = \"test_endpoint\"\n",
    "VS_INDEX_NAME = \"FM_API_EXAMPLES_VS_INDEX\"\n",
    "SOURCE_TABLE_NAME = \"FM_API_EXAMPLES_DATA\"\n",
    "\n",
    "VS_INDEX_FULLNAME = f\"{CATALOG}.{DB}.{VS_INDEX_NAME}\"\n",
    "SOURCE_TABLE_FULLNAME = f\"{CATALOG}.{DB}.{SOURCE_TABLE_NAME}\"\n",
    "DATABRICKS_TOKEN = dbutils.secrets.get(scope=\"daniel.liden\", key=\"rag_demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd132365-7270-4448-be38-6d6ce1c21b80",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create Catalog, Schema, and Table\n",
    "\n",
    "A Databricks Vector Search Index is created from a Delta Table. The source Delta Table includes the data we ultimately want to index and search with the vector database. In this cell, we create the catalog, schema, and source table from which we will create the vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4dbac4b-2852-4b49-9e43-f514aca70a92",
     "showTitle": true,
     "title": "Pyspark Schema Volume Table Setup"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up schema/volume/table\n",
    "from pyspark.sql.types import StructType, StructField, StringType, ArrayType, FloatType\n",
    "\n",
    "spark.sql(f\"CREATE CATALOG IF NOT EXISTS {CATALOG}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG}.{DB}\")\n",
    "spark.sql(\n",
    "    f\"\"\"CREATE TABLE IF NOT EXISTS {SOURCE_TABLE_FULLNAME} (\n",
    "        id STRING,\n",
    "        text STRING,\n",
    "        date DATE,\n",
    "        title STRING\n",
    "    )\n",
    "    USING delta \n",
    "    TBLPROPERTIES ('delta.enableChangeDataFeed' = 'true')\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae01c282-4207-4393-866d-dd4eece96633",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Set up the Vector Database\n",
    "Next, we set up the vector database. There are three key steps:\n",
    "1. Initialize the vector search client\n",
    "2. Create the endpoint\n",
    "3. Create the index using the source Delta table we created earlier and the `bge-large-en` embeddings model from the Foundation Model API\n",
    "\n",
    "### Initialize the Vector Search Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3348acab-c299-4d2f-b97a-c49affc1abd8",
     "showTitle": true,
     "title": "Vector Search Client Initialization"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True to VectorSearchClient().\n"
     ]
    }
   ],
   "source": [
    "from databricks.vector_search.client import VectorSearchClient\n",
    "vsc = VectorSearchClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66477546-4d73-47de-bd3a-de0400a6e906",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create the Endpoint\n",
    "\n",
    "The cell below will check if the endpoint already exists and create it if it does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be184f2c-a1e9-44df-8d63-7225ec0db655",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint already exists.\n"
     ]
    }
   ],
   "source": [
    "if not VS_ENDPOINT_NAME in [endpoint[\"name\"] for endpoint in vsc.list_endpoints()['endpoints']]:\n",
    "    vsc.create_endpoint(VS_ENDPOINT_NAME)\n",
    "else:\n",
    "    print(\"Endpoint already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aa900a70-7b23-4a68-989c-93ba34a6c16c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create the Vector Index\n",
    "\n",
    "Now we can create the index over the Delta table we created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "604edff9-24cc-484d-bfd9-002dc820ebfc",
     "showTitle": true,
     "title": "Python Delta Sync Index Setup"
    }
   },
   "outputs": [],
   "source": [
    "# set up an index with managed embeddings\n",
    "i=vsc.create_delta_sync_index(\n",
    "    endpoint_name=VS_ENDPOINT_NAME,\n",
    "    index_name=VS_INDEX_FULLNAME,\n",
    "    source_table_name=SOURCE_TABLE_FULLNAME,\n",
    "    pipeline_type=\"TRIGGERED\",\n",
    "    primary_key=\"id\",\n",
    "    embedding_source_column=\"text\",\n",
    "    embedding_model_endpoint_name=\"databricks-bge-large-en\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "959b6ce8-78a3-4496-8009-fb28e21be36a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    " There are a few key points to note about the specific configuration we used in this case:\n",
    "- We used `pipeline_type=\"TRIGGERED\"`. This requires us to use the index's `sync()` method to manually sync the source Delta table with the index. We could, alternatively, use `pipeline_type=\"CONTINUOUS\"` which will automatically keep the index in sync with the source table with only seconds of latency. This approach is more costly, though, as a compute cluster must be provisioned for the continuous sync streaming pipeline.\n",
    "- We specified `embedding_model_endpoint_name=\"databricks-bge-large-en\"`. We can use any embedding model available via model serving; this is the name of the pay-per-token Foundation Model API version of `databricks-bge-large-en`. By passing an `embedding_source_column` and `embedding_model_endpoint_name`, we configure the index such that it will automatically use the model to generate embeddings for the texts in the `text` column of the source table. We do not need to manually generate embeddings.\n",
    "\n",
    "  If, however, we did want to manage embeddings manually, we could include the following arguments instead:\n",
    "\n",
    "  ```\n",
    "    embedding_vector_column=\"<embedding_column>\",\n",
    "    embedding_dimension=<embedding_dimension>\n",
    "  ```\n",
    "\n",
    "  In the latter approach, we include a column for embeddings in the source delta table and embeddings are *not* computed automatically from the text column.\n",
    "\n",
    "## Set up some example texts\n",
    "\n",
    "Now we set up some example texts to index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28b54ae9-fe2d-4c94-9ee7-34921ee43476",
     "showTitle": true,
     "title": "Smart Initiative: Strategic Management for Achieving Results through Efficiency and Resources"
    }
   },
   "outputs": [],
   "source": [
    "# Some example texts\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "smarter_overview = {\"text\":\"\"\"\n",
    "S.M.A.R.T.E.R. Initiative: Strategic Management for Achieving Results through Efficiency and Resources\n",
    "Introduction\n",
    "The S.M.A.R.T.E.R. Initiative, standing for \"Strategic Management for Achieving Results through Efficiency and Resources,\" is a groundbreaking project aimed at revolutionizing the way our organization operates. In today's rapidly changing business landscape, achieving success demands a strategic approach that leverages resources effectively while optimizing efficiency. The S.M.A.R.T.E.R. Initiative is designed to do just that.\n",
    "\n",
    "Background\n",
    "As markets evolve and competition intensifies, organizations must adapt to stay relevant and profitable. Traditional methods of operation often become inefficient and costly. The S.M.A.R.T.E.R. Initiative was conceived as a response to this challenge, with the primary goal of enhancing strategic management practices to achieve better results.\n",
    "\n",
    "Objectives\n",
    "1. Resource Optimization\n",
    "One of the key objectives of the S.M.A.R.T.E.R. Initiative is to optimize resource allocation. This involves identifying underutilized resources, streamlining processes, and reallocating resources to areas that contribute most to our strategic goals.\n",
    "\n",
    "2. Efficiency Improvement\n",
    "Efficiency is at the core of the S.M.A.R.T.E.R. Initiative. By identifying bottlenecks and improving processes, we aim to reduce operational costs, shorten project timelines, and enhance overall productivity.\n",
    "\n",
    "3. Strategic Alignment\n",
    "For any organization to succeed, its activities must be aligned with its strategic objectives. The S.M.A.R.T.E.R. Initiative will ensure that every action and resource allocation is in sync with our long-term strategic goals.\n",
    "\n",
    "4. Results-driven Approach\n",
    "The ultimate measure of success is results. The S.M.A.R.T.E.R. Initiative will foster a results-driven culture within our organization, where decisions and actions are guided by their impact on our bottom line and strategic objectives.\n",
    "\n",
    "Key Components\n",
    "The S.M.A.R.T.E.R. Initiative comprises several key components:\n",
    "\n",
    "1. Data Analytics and Insights\n",
    "Data is the foundation of informed decision-making. We will invest in advanced data analytics tools to gain insights into our operations, customer behavior, and market trends. These insights will guide our resource allocation and strategy.\n",
    "\n",
    "2. Process Automation\n",
    "Automation will play a vital role in enhancing efficiency. Routine and repetitive tasks will be automated, freeing up our workforce to focus on more strategic activities.\n",
    "\n",
    "3. Performance Metrics and KPIs\n",
    "To ensure that our efforts are aligned with our objectives, we will establish a comprehensive set of Key Performance Indicators (KPIs). Regular monitoring and reporting will provide visibility into our progress.\n",
    "\n",
    "4. Training and Development\n",
    "Enhancing our workforce's skills is essential. We will invest in training and development programs to equip our employees with the knowledge and tools needed to excel in their roles.\n",
    "\n",
    "Implementation Timeline\n",
    "The S.M.A.R.T.E.R. Initiative will be implemented in phases over the next three years. This phased approach allows for a smooth transition and ensures that each component is integrated effectively into our operations.\n",
    "\n",
    "Conclusion\n",
    "The S.M.A.R.T.E.R. Initiative represents a significant step forward for our organization. By strategically managing our resources and optimizing efficiency, we are positioning ourselves for sustained success in a competitive marketplace. This initiative is a testament to our commitment to excellence and our dedication to achieving exceptional results.\n",
    "\n",
    "As we embark on this journey, we look forward to the transformative impact that the S.M.A.R.T.E.R. Initiative will have on our organization and the benefits it will bring to our employees, customers, and stakeholders.\n",
    "\"\"\", \"title\": \"Project Kickoff\", \"date\": datetime.strptime(\"2024-01-16\", \"%Y-%m-%d\")}\n",
    "\n",
    "smarter_kpis = {\"text\": \"\"\"S.M.A.R.T.E.R. Initiative: Key Performance Indicators (KPIs)\n",
    "Introduction\n",
    "The S.M.A.R.T.E.R. Initiative (Strategic Management for Achieving Results through Efficiency and Resources) is designed to drive excellence within our organization. To measure the success and effectiveness of this initiative, we have established three concrete and measurable Key Performance Indicators (KPIs). This document outlines these KPIs and their associated targets.\n",
    "\n",
    "Key Performance Indicators (KPIs)\n",
    "1. Resource Utilization Efficiency (RUE)\n",
    "Objective: To optimize resource utilization for cost-efficiency.\n",
    "\n",
    "KPI Definition: RUE will be calculated as (Actual Resource Utilization / Planned Resource Utilization) * 100%.\n",
    "\n",
    "Target: Achieve a 15% increase in RUE within the first year.\n",
    "\n",
    "2. Time-to-Decision Reduction (TDR)\n",
    "Objective: To streamline operational processes and reduce decision-making time.\n",
    "\n",
    "KPI Definition: TDR will be calculated as (Pre-Initiative Decision Time - Post-Initiative Decision Time) / Pre-Initiative Decision Time.\n",
    "\n",
    "Target: Achieve a 20% reduction in TDR for critical business decisions.\n",
    "\n",
    "3. Strategic Goals Achievement (SGA)\n",
    "Objective: To ensure that organizational activities align with strategic goals.\n",
    "\n",
    "KPI Definition: SGA will measure the percentage of predefined strategic objectives achieved.\n",
    "\n",
    "Target: Achieve an 80% Strategic Goals Achievement rate within two years.\n",
    "\n",
    "Conclusion\n",
    "These three KPIs, Resource Utilization Efficiency (RUE), Time-to-Decision Reduction (TDR), and Strategic Goals Achievement (SGA), will serve as crucial metrics for evaluating the success of the S.M.A.R.T.E.R. Initiative. By tracking these KPIs and working towards their targets, we aim to drive efficiency, optimize resource utilization, and align our actions with our strategic objectives. This focus on measurable outcomes will guide our efforts towards achieving excellence within our organization.\"\"\",\n",
    "\"title\": \"Project KPIs\", \"date\": datetime.strptime(\"2024-01-16\", \"%Y-%m-%d\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0cbc5c1-2ea1-484e-8910-a989abdb7384",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Chunk the texts\n",
    "Typically, when using a vector database for retrieval-augmented generation (RAG) tasks, we break the texts apart into smaller (and sometimes overlapping) chunks in order to return focused and relevant information without returning an excessive amount of text.\n",
    "\n",
    "In the code below, we break the sample texts above into shorter overlapping text chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "feb4b55d-2935-4571-96e1-eec742466327",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def chunk_text(text, chunk_size, overlap):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    index = 0\n",
    "\n",
    "    while index < len(words):\n",
    "        end = index + chunk_size\n",
    "        while end < len(words) and not re.match(r'.*[.!?]\\s*$', words[end]):\n",
    "            end += 1\n",
    "        chunk = ' '.join(words[index:end+1])\n",
    "        chunks.append(chunk)\n",
    "        index += chunk_size - overlap\n",
    "\n",
    "    return chunks\n",
    "\n",
    "chunks = []\n",
    "documents = [smarter_overview, smarter_kpis]\n",
    "\n",
    "for document in documents:\n",
    "    for i, c in enumerate(chunk_text(document[\"text\"], 150, 25)):\n",
    "        chunk = {}\n",
    "        chunk[\"text\"] = c\n",
    "        chunk[\"title\"] = document[\"title\"]\n",
    "        chunk[\"date\"] = document[\"date\"]\n",
    "        chunk[\"id\"] = document[\"title\"] + \"_\" + str(i)\n",
    "\n",
    "        chunks.append(chunk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "76cbcd7a-6ac9-414c-90dd-c938f0ea4c93",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Insert the text chunks into the source delta table\n",
    "\n",
    "Now we save the chunks, along with some metadata (a document title, date, and a unique id) to the source delta table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27b8a7ba-32eb-4829-a560-1dd210ede177",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, ArrayType, FloatType, DateType\n",
    "\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"id\", StringType(), True),\n",
    "        StructField(\"text\", StringType(), True),\n",
    "        StructField(\"title\", StringType(), True),\n",
    "        StructField(\"date\", DateType(), True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "if chunks:\n",
    "    result_df = spark.createDataFrame(chunks, schema=schema)\n",
    "    result_df.write.format(\"delta\").mode(\"append\").saveAsTable(\n",
    "        SOURCE_TABLE_FULLNAME\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b76ab35e-f967-468c-97c4-67c0e4f6c1c4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Sync the Vector Search Index\n",
    "Because we specified `pipeline_type=\"TRIGGERED\"` when configuring the Delta Index, we still need to manually tell the index to sync with the delta table. This will take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ef5b5b3-7105-4e5b-a604-c7994be6df61",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sync\n",
    "index = vsc.get_index(endpoint_name=VS_ENDPOINT_NAME,\n",
    "                      index_name=VS_INDEX_FULLNAME)\n",
    "index.sync()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "560389ad-157f-4c87-91b2-a6bc911b3e81",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Query the Vector Index\n",
    "\n",
    "Now that we have added our text chunks to the source delta table and synced it with the Vector Search index, we're ready to query the index! We do this with the `index.similarity_search()` method.\n",
    "\n",
    "The `columns` argument takes a list of the columns we want returned; in this case, we request the text and title columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c088bddc-48b7-46ab-ad8d-7072883923a4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'manifest': {'column_count': 3,\n",
       "  'columns': [{'name': 'text'}, {'name': 'title'}, {'name': 'score'}]},\n",
       " 'result': {'row_count': 3,\n",
       "  'data_array': [['S.M.A.R.T.E.R. Initiative: Key Performance Indicators (KPIs) Introduction The S.M.A.R.T.E.R. Initiative (Strategic Management for Achieving Results through Efficiency and Resources) is designed to drive excellence within our organization. To measure the success and effectiveness of this initiative, we have established three concrete and measurable Key Performance Indicators (KPIs). This document outlines these KPIs and their associated targets. Key Performance Indicators (KPIs) 1. Resource Utilization Efficiency (RUE) Objective: To optimize resource utilization for cost-efficiency. KPI Definition: RUE will be calculated as (Actual Resource Utilization / Planned Resource Utilization) * 100%. Target: Achieve a 15% increase in RUE within the first year. 2. Time-to-Decision Reduction (TDR) Objective: To streamline operational processes and reduce decision-making time. KPI Definition: TDR will be calculated as (Pre-Initiative Decision Time - Post-Initiative Decision Time) / Pre-Initiative Decision Time. Target: Achieve a 20% reduction in TDR for critical business decisions. 3. Strategic Goals Achievement (SGA) Objective: To ensure that organizational activities align with strategic goals.',\n",
       "    'Project KPIs',\n",
       "    0.56844866],\n",
       "   ['Time) / Pre-Initiative Decision Time. Target: Achieve a 20% reduction in TDR for critical business decisions. 3. Strategic Goals Achievement (SGA) Objective: To ensure that organizational activities align with strategic goals. KPI Definition: SGA will measure the percentage of predefined strategic objectives achieved. Target: Achieve an 80% Strategic Goals Achievement rate within two years. Conclusion These three KPIs, Resource Utilization Efficiency (RUE), Time-to-Decision Reduction (TDR), and Strategic Goals Achievement (SGA), will serve as crucial metrics for evaluating the success of the S.M.A.R.T.E.R. Initiative. By tracking these KPIs and working towards their targets, we aim to drive efficiency, optimize resource utilization, and align our actions with our strategic objectives. This focus on measurable outcomes will guide our efforts towards achieving excellence within our organization.',\n",
       "    'Project KPIs',\n",
       "    0.5681397],\n",
       "   ['S.M.A.R.T.E.R. Initiative is to optimize resource allocation. This involves identifying underutilized resources, streamlining processes, and reallocating resources to areas that contribute most to our strategic goals. 2. Efficiency Improvement Efficiency is at the core of the S.M.A.R.T.E.R. Initiative. By identifying bottlenecks and improving processes, we aim to reduce operational costs, shorten project timelines, and enhance overall productivity. 3. Strategic Alignment For any organization to succeed, its activities must be aligned with its strategic objectives. The S.M.A.R.T.E.R. Initiative will ensure that every action and resource allocation is in sync with our long-term strategic goals. 4. Results-driven Approach The ultimate measure of success is results. The S.M.A.R.T.E.R. Initiative will foster a results-driven culture within our organization, where decisions and actions are guided by their impact on our bottom line and strategic objectives. Key Components The S.M.A.R.T.E.R. Initiative comprises several key components: 1. Data Analytics and Insights Data is the foundation of informed decision-making.',\n",
       "    'Project Kickoff',\n",
       "    0.55467147]]},\n",
       " 'next_page_token': '',\n",
       " 'debug_info': {'response_time': 897.0,\n",
       "  'ann_time': 179.0,\n",
       "  'embedding_gen_time': 534.0}}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query\n",
    "index.similarity_search(columns=[\"text\", \"title\"],\n",
    "                        query_text=\"What is the TDR Target for the SMARTER initiative?\",\n",
    "                        num_results = 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "72d7debe-29a6-4a7b-b73e-72374f507936",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Using the UI\n",
    "Most of the Vector Database management steps above can be done via the UI: you can [create an endpoint](https://docs.databricks.com/en/generative-ai/create-query-vector-search.html#create-a-vector-search-endpoint-using-the-ui), [create an index](https://docs.databricks.com/en/generative-ai/create-query-vector-search.html#create-index-using-the-ui), sync the index, and more via the UI in the Databricks Catalog Explorer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "84ffe039-7033-4c4f-92d6-38cf1cc44178",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Cleanup\n",
    "The code snippet below will delete the VS index and source table, along with the catalog and schema if they are empty. Uncomment and run these cells if you are finished with the example and want to delete the generated artifacts.\n",
    "\n",
    "Please carefully inspect the objects you used in this guide to ensure you are not deleting any shared resources or anything else you do not want deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef39e064-deca-4eff-82d4-09a37af525ea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## delete index\n",
    "# vsc.delete_index(endpoint_name=VS_ENDPOINT_NAME,\n",
    "#                   index_name=VS_INDEX_FULLNAME)\n",
    "\n",
    "# delete schema and catalog\n",
    "# spark.sql(f\"DROP CATALOG IF EXISTS {CATALOG} CASCADE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "726f4821-4cd6-4a8f-bc2d-9d4f2345e651",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Delete Endpoint\n",
    "# vsc.delete_endpoint(VS_ENDPOINT_NAME)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2531914303109755,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Using Databricks Vector Search with the Foundation Model API",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "hfnlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
