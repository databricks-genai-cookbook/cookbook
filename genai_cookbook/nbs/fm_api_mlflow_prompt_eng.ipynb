{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(nbs:fm_api_mlflow_prompt_eng)=\n",
    "# Using the MLflow Prompt Engineering UI\n",
    "\n",
    "This notebook will show how to use the MLflow Prompt Engineering UI with the Databricks Foundation Model API. The [prompt engineering UI](https://mlflow.org/docs/latest/llms/prompt-engineering/index.html) lets you combine different models, prompts, and parameter configurations and works seamlessly with the Foundation Model API in Databricks.\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "### Navigate to the MLflow Experiment UI\n",
    "\n",
    "First, assuming you are starting from a Databricks Notebook environment, launch the MLflow Experiment UI. Click the \"MLflow Experiments\" icon and then click the \"View Experiment UI\" button, as shown in the following screenshot.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{image} ../images/prompt_eng_ui_img/prompt_eng_ui_1.png\n",
    ":alt: Launching the MLflow Experiment UI\n",
    ":width: 800px\n",
    ":align: center\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start a New MLflow Run using Prompt Engineering\n",
    "\n",
    "Next, click \"+New Run\" and select \"using Prompt Engineering\" as shown in the image below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{image} ../images/prompt_eng_ui_img/prompt_eng_ui_2.png\n",
    ":alt: Starting a new MLflow Run\n",
    ":width: 800px\n",
    ":align: center\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select a Foundation Model API Model\n",
    "\n",
    "Models from the foundation model API start with `databricks-`. Select a model from the \"Served LLM Model\" dropdown.\n",
    "\n",
    "```{image} ../images/prompt_eng_ui_img/prompt_eng_ui_3.png\n",
    ":alt: Selecting a Foundation Model API model\n",
    ":width: 800px\n",
    ":align: center\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill Out the Prompt Template\n",
    "\n",
    "The Prompt Engineering UI allows you to compare the performance of different prompts and different models using a the same prompt template. In the example below, we simulate a RAG scenario and provide a source text about Delta Lake. We then configure a variable called \"question\", formatted `{{ question }}`, where user prompts will be inserted. We can see how different prompts and models operate with this same template.\n",
    "\n",
    "```{image} ../images/prompt_eng_ui_img/prompt_eng_ui_4.png\n",
    ":alt: Filling out the prompt template\n",
    ":width: 800px\n",
    ":align: center\n",
    "```\n",
    "\n",
    "Note that, at this phase, you can also configure some model generation parameters, specifically \"temperature,\" \"Max tokens,\" and \"Stop Sequences.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the first Run\n",
    "\n",
    "After filling out the prompt template, fill out an initial question, click \"Evaluate\", and then click \"Create run\" at the bottom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{image} ../images/prompt_eng_ui_img/prompt_eng_ui_5.png\n",
    ":alt: launching the prompt engineering ui\n",
    ":width: 800px\n",
    ":align: center\n",
    "```\n",
    "\n",
    "## Adding new prompts and new runs\n",
    "\n",
    "At this point, you can see a table with one row (for the initial question) and one column (for the initial model). You can add new questions, which will be inserted into the same template, and new models, which you can evaluate on the same questions.\n",
    "\n",
    "To add a new question, click the \"+\" button on the left side of the table and enter the question.\n",
    "\n",
    "To add a new model, click the \"+ New run\" button on the upper right side of the interface and repeat the process above for the new model. You can also use the new run interface to configure different templates and variables.\n",
    "\n",
    "```{image} ../images/prompt_eng_ui_img/prompt_eng_ui_6.png\n",
    ":alt: Adding new prompts and models\n",
    ":width: 800px\n",
    ":align: center\n",
    "```\n",
    "\n",
    "## Evaluating cells after adding new prompts or models\n",
    "\n",
    "Adding new prompts or models does not automatically evaluate all combinations of models and prompts. To evaluate after adding new models/prompts, click the \"Evaluate\" button in empty cells or \"Evaluate all\" in the column (run) headers.\n",
    "\n",
    "```{image} ../images/prompt_eng_ui_img/prompt_eng_ui_7.png\n",
    ":alt: Evaluating cells\n",
    ":width: 800px\n",
    ":align: center\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
